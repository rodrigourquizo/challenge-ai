{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8a26f67",
   "metadata": {},
   "source": [
    "# Challenge AI: Detección de Fraudes en Transacciones Bancarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "041f782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Job</th>\n",
       "      <th>Housing</th>\n",
       "      <th>Saving accounts</th>\n",
       "      <th>Checking account</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>NaN</td>\n",
       "      <td>little</td>\n",
       "      <td>1169</td>\n",
       "      <td>6</td>\n",
       "      <td>radio/TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>female</td>\n",
       "      <td>2</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>moderate</td>\n",
       "      <td>5951</td>\n",
       "      <td>48</td>\n",
       "      <td>radio/TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>own</td>\n",
       "      <td>little</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2096</td>\n",
       "      <td>12</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>7882</td>\n",
       "      <td>42</td>\n",
       "      <td>furniture/equipment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>2</td>\n",
       "      <td>free</td>\n",
       "      <td>little</td>\n",
       "      <td>little</td>\n",
       "      <td>4870</td>\n",
       "      <td>24</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age     Sex  Job Housing Saving accounts Checking account  Credit amount  \\\n",
       "0   67    male    2     own             NaN           little           1169   \n",
       "1   22  female    2     own          little         moderate           5951   \n",
       "2   49    male    1     own          little              NaN           2096   \n",
       "3   45    male    2    free          little           little           7882   \n",
       "4   53    male    2    free          little           little           4870   \n",
       "\n",
       "   Duration              Purpose  \n",
       "0         6             radio/TV  \n",
       "1        48             radio/TV  \n",
       "2        12            education  \n",
       "3        42  furniture/equipment  \n",
       "4        24                  car  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import time\n",
    "\n",
    "df = pd.read_excel('credir_risk_reto.csv.xlsx')\n",
    "bedrock = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ccb90",
   "metadata": {},
   "source": [
    "Generación de descripciones con Bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79763f",
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = []\n",
    "for i in range(len(df)):\n",
    "    fila = df.iloc[i]  \n",
    "    \n",
    "    ahorros = fila['Saving accounts'] if fila['Saving accounts'] else 'desconocido'\n",
    "    cuenta_corriente = fila['Checking account'] if fila['Checking account'] else 'desconocido'\n",
    "    mapa_trabajo = {0: 'no cualificado no residente', 1: 'no cualificado residente', 2: 'cualificado', 3: 'altamente cualificado'}\n",
    "    desc_trabajo = mapa_trabajo.get(fila['Job'], 'desconocido')\n",
    "\n",
    "    #Crear prompt\n",
    "    prompt = f\"\"\"\n",
    "    Genera UNA descripción concisa del perfil de riesgo crediticio para una persona con estas características en UNA linea, DETENIÉNDOTE después de aproximadamente 50 palabras:\n",
    "    - Edad: {fila['Age']}\n",
    "    - Sexo: {fila['Sex']}\n",
    "    - Trabajo: {desc_trabajo}\n",
    "    - Vivienda: {fila['Housing']}\n",
    "    - Cuentas de ahorro: {ahorros}\n",
    "    - Cuenta corriente: {cuenta_corriente}\n",
    "    - Monto de crédito: {fila['Credit amount']} EUR\n",
    "    - Duración: {fila['Duration']} meses\n",
    "    - Propósito: {fila['Purpose']}\n",
    "\n",
    "    Evalúa el riesgo crediticio en solo un párrafo corto, sin repeticiones ni preguntas, ni contenido adicional\n",
    "    Al final indica si es “bad risk” o “good risk”,asegurando que la evaluación sea coherente con la clasificación, solo una de esas dos opciones, sin explicaciones adicionales.\n",
    "    Si el riesgo crediticio es \"moderado a alto\" se tiene que clasificar como \"bad risk\" a menos que haya factores compensatorios fuertes (e.g., ahorros significativos).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": 0.6,\n",
    "        #\"max_tokens\": 100\n",
    "    })\n",
    "    try:\n",
    "        response = bedrock.invoke_model(\n",
    "            modelId='arn:aws:bedrock:us-east-1:004082821794:inference-profile/us.meta.llama3-2-90b-instruct-v1:0',\n",
    "            contentType='application/json',\n",
    "            accept='application/json',\n",
    "            body=body\n",
    "        )\n",
    "        response_body = json.loads(response['body'].read())\n",
    "        \n",
    "        if 'generation' in response_body: \n",
    "            description = response_body['generation'].strip()\n",
    "        else:\n",
    "            description = \"No se pudo extraer la descripción.\"\n",
    "        #print(f\"Respuesta completa para fila {i}: {description}\")\n",
    "        \n",
    "        descriptions.append(description)\n",
    "    except Exception as e:\n",
    "        print(f\"Error en fila {i}: {e}\")\n",
    "        descriptions.append(\"No se pudo generar la descripción.\")\n",
    "    time.sleep(1)\n",
    "\n",
    "# Asignar las descripciones al DataFrame\n",
    "df.loc[:, 'description'] = descriptions\n",
    "df.to_excel('credit_risk_with_descriptions.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644b1c6",
   "metadata": {},
   "source": [
    "Clasificación y etiquetado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c5476417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('credit_risk_with_descriptions.xlsx')\n",
    "\n",
    "def extraer_target(descripcion):\n",
    "    if 'good risk' in descripcion.lower():\n",
    "        return 'good risk'\n",
    "    if 'buen riesgo' in descripcion.lower():\n",
    "        return 'good risk'\n",
    "    if 'bad risk' in descripcion.lower():\n",
    "        return 'bad risk'\n",
    "    if 'mal riesgo' in descripcion.lower():\n",
    "        return 'bad risk'\n",
    "\n",
    "df['target'] = df['description'].apply(extraer_target)\n",
    "\n",
    "df.to_excel('credit_risk_labeled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a51740b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "bad risk     657\n",
       "good risk    343\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Distribución de clases\n",
    "target_counts = df['target'].value_counts().sort_index()  # Contar 'good risk' y 'bad risk'\n",
    "target_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3fd39",
   "metadata": {},
   "source": [
    "Preprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31679c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporcion de clases en la data de entrenamiento: target\n",
      "1    528\n",
      "0    272\n",
      "Name: count, dtype: int64\n",
      "Proporcion de clases en la data de prueba: target\n",
      "1    129\n",
      "0     71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_excel('credit_risk_labeled.xlsx')\n",
    "\n",
    "df['target'] = df['target'].map({'good risk': 0, 'bad risk': 1})\n",
    "\n",
    "if df['Sex'].dtype == 'object':\n",
    "    df['Sex'] = df['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "df['Housing'] = df['Housing'].map({'free': 0, 'rent': 1, 'own': 2})\n",
    "\n",
    "df['Saving accounts'] = df['Saving accounts'].map({\n",
    "    'little': 0, 'moderate': 1, 'quite rich': 2, 'rich': 3\n",
    "})\n",
    "\n",
    "df['Checking account'] = df['Checking account'].map({\n",
    "    'little': 0, 'moderate': 1, 'rich': 2\n",
    "})\n",
    "\n",
    "numeric_columns = ['Age', 'Sex', 'Job', 'Housing', 'Saving accounts', 'Checking account', 'Credit amount', 'Duration']\n",
    "categorical_columns = ['Purpose']\n",
    "\n",
    "X_numeric = df[numeric_columns].values\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_categorical = encoder.fit_transform(df[categorical_columns])\n",
    "\n",
    "X = np.hstack((X_numeric, X_categorical))\n",
    "y = df['target'].values\n",
    "\n",
    "numeric_names = numeric_columns\n",
    "categorical_names = [f\"{col}_{cat}\" for col, cats in zip(categorical_columns, encoder.categories_) for cat in cats]\n",
    "all_feature_names = numeric_names + categorical_names\n",
    "\n",
    "X_df = pd.DataFrame(X, columns=all_feature_names)\n",
    "final_df = pd.concat([ pd.Series(y, name='target'),X_df], axis=1)\n",
    "\n",
    "train_df = final_df.sample(frac=0.8, random_state=42)\n",
    "test_df = final_df.drop(train_df.index)\n",
    "\n",
    "#Debemos verificar que la distribución de clases sea similar a la del dataset total, lo que reflejara la distribucion real del problema de riesgo crediticio\n",
    "print(\"Proporcion de clases en la data de entrenamiento:\", train_df[\"target\"].value_counts())\n",
    "print(\"Proporcion de clases en la data de prueba:\", test_df[\"target\"].value_counts())\n",
    "\n",
    "train_df.to_csv('credit_risk_processed_train.csv', index=False, header=False)\n",
    "test_df.to_csv('credit_risk_processed_test.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a674683",
   "metadata": {},
   "source": [
    "Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3aad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-07-24-02-32-10-685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-24 02:32:12 Starting - Starting the training job...\n",
      "2025-07-24 02:32:48 Downloading - Downloading input data...\n",
      "2025-07-24 02:33:18 Downloading - Downloading the training image......\n",
      "2025-07-24 02:34:14 Training - Training image download completed. Training in progress.../miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "[2025-07-24 02:34:32.099 ip-10-2-172-41.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2025-07-24 02:34:32.122 ip-10-2-172-41.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\n",
      "[2025-07-24:02:34:32:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "[2025-07-24:02:34:32:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\n",
      "Returning the value itself\n",
      "[2025-07-24:02:34:32:INFO] No GPUs detected (normal if no gpus installed)\n",
      "[2025-07-24:02:34:32:INFO] Running XGBoost Sagemaker in algorithm mode\n",
      "[2025-07-24:02:34:32:INFO] Determined 0 GPU(s) available on the instance.\n",
      "[2025-07-24:02:34:32:INFO] Determined delimiter of CSV input is ','\n",
      "[2025-07-24:02:34:32:INFO] files path: /opt/ml/input/data/train\n",
      "[2025-07-24:02:34:32:INFO] Determined delimiter of CSV input is ','\n",
      "[2025-07-24:02:34:32:INFO] Single node training.\n",
      "[2025-07-24:02:34:32:INFO] Train matrix has 800 rows and 16 columns\n",
      "[2025-07-24 02:34:32.530 ip-10-2-172-41.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\n",
      "[2025-07-24 02:34:32.531 ip-10-2-172-41.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\n",
      "[2025-07-24 02:34:32.531 ip-10-2-172-41.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\n",
      "[2025-07-24 02:34:32.532 ip-10-2-172-41.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\n",
      "[2025-07-24:02:34:32:INFO] Debug hook created from config\n",
      "[02:34:32] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]#011train-logloss:0.61761\n",
      "[2025-07-24 02:34:32.569 ip-10-2-172-41.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\n",
      "[2025-07-24 02:34:32.575 ip-10-2-172-41.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\n",
      "[1]#011train-logloss:0.56180\n",
      "[2]#011train-logloss:0.52289\n",
      "[3]#011train-logloss:0.48945\n",
      "[4]#011train-logloss:0.46495\n",
      "[5]#011train-logloss:0.44652\n",
      "[6]#011train-logloss:0.43227\n",
      "[7]#011train-logloss:0.42006\n",
      "[8]#011train-logloss:0.40944\n",
      "[9]#011train-logloss:0.39658\n",
      "[10]#011train-logloss:0.38710\n",
      "[11]#011train-logloss:0.37431\n",
      "[12]#011train-logloss:0.36095\n",
      "[13]#011train-logloss:0.35360\n",
      "[14]#011train-logloss:0.34153\n",
      "[15]#011train-logloss:0.33137\n",
      "[16]#011train-logloss:0.32493\n",
      "[17]#011train-logloss:0.31995\n",
      "[18]#011train-logloss:0.31124\n",
      "[19]#011train-logloss:0.30445\n",
      "[20]#011train-logloss:0.29792\n",
      "[21]#011train-logloss:0.29031\n",
      "[22]#011train-logloss:0.28355\n",
      "[23]#011train-logloss:0.27745\n",
      "[24]#011train-logloss:0.27304\n",
      "[25]#011train-logloss:0.26796\n",
      "[26]#011train-logloss:0.26531\n",
      "[27]#011train-logloss:0.25944\n",
      "[28]#011train-logloss:0.25699\n",
      "[29]#011train-logloss:0.25468\n",
      "[30]#011train-logloss:0.25042\n",
      "[31]#011train-logloss:0.24778\n",
      "[32]#011train-logloss:0.24333\n",
      "[33]#011train-logloss:0.24038\n",
      "[34]#011train-logloss:0.23698\n",
      "[35]#011train-logloss:0.23201\n",
      "[36]#011train-logloss:0.22981\n",
      "[37]#011train-logloss:0.22539\n",
      "[38]#011train-logloss:0.22158\n",
      "[39]#011train-logloss:0.21661\n",
      "[40]#011train-logloss:0.21157\n",
      "[41]#011train-logloss:0.20787\n",
      "[42]#011train-logloss:0.20564\n",
      "[43]#011train-logloss:0.20061\n",
      "[44]#011train-logloss:0.19736\n",
      "[45]#011train-logloss:0.19415\n",
      "[46]#011train-logloss:0.19167\n",
      "[47]#011train-logloss:0.18799\n",
      "[48]#011train-logloss:0.18560\n",
      "[49]#011train-logloss:0.18226\n",
      "[50]#011train-logloss:0.18049\n",
      "[51]#011train-logloss:0.17702\n",
      "[52]#011train-logloss:0.17519\n",
      "[53]#011train-logloss:0.17228\n",
      "[54]#011train-logloss:0.17029\n",
      "[55]#011train-logloss:0.16793\n",
      "[56]#011train-logloss:0.16643\n",
      "[57]#011train-logloss:0.16323\n",
      "[58]#011train-logloss:0.16094\n",
      "[59]#011train-logloss:0.15860\n",
      "[60]#011train-logloss:0.15604\n",
      "[61]#011train-logloss:0.15441\n",
      "[62]#011train-logloss:0.15221\n",
      "[63]#011train-logloss:0.15040\n",
      "[64]#011train-logloss:0.14814\n",
      "[65]#011train-logloss:0.14549\n",
      "[66]#011train-logloss:0.14340\n",
      "[67]#011train-logloss:0.14155\n",
      "[68]#011train-logloss:0.13799\n",
      "[69]#011train-logloss:0.13679\n",
      "[70]#011train-logloss:0.13547\n",
      "[71]#011train-logloss:0.13354\n",
      "[72]#011train-logloss:0.13192\n",
      "[73]#011train-logloss:0.12942\n",
      "[74]#011train-logloss:0.12859\n",
      "[75]#011train-logloss:0.12658\n",
      "[76]#011train-logloss:0.12507\n",
      "[77]#011train-logloss:0.12399\n",
      "[78]#011train-logloss:0.12244\n",
      "[79]#011train-logloss:0.12069\n",
      "[80]#011train-logloss:0.11963\n",
      "[81]#011train-logloss:0.11801\n",
      "[82]#011train-logloss:0.11672\n",
      "[83]#011train-logloss:0.11508\n",
      "[84]#011train-logloss:0.11386\n",
      "[85]#011train-logloss:0.11302\n",
      "[86]#011train-logloss:0.11125\n",
      "[87]#011train-logloss:0.11023\n",
      "[88]#011train-logloss:0.10915\n",
      "[89]#011train-logloss:0.10778\n",
      "[90]#011train-logloss:0.10705\n",
      "[91]#011train-logloss:0.10630\n",
      "[92]#011train-logloss:0.10591\n",
      "[93]#011train-logloss:0.10490\n",
      "[94]#011train-logloss:0.10335\n",
      "[95]#011train-logloss:0.10250\n",
      "[96]#011train-logloss:0.10180\n",
      "[97]#011train-logloss:0.10063\n",
      "[98]#011train-logloss:0.09963\n",
      "[99]#011train-logloss:0.09887\n",
      "\n",
      "2025-07-24 02:34:53 Uploading - Uploading generated training model\n",
      "2025-07-24 02:34:53 Completed - Training job completed\n",
      "Training seconds: 124\n",
      "Billable seconds: 124\n",
      "Training job sagemaker-xgboost-2025-07-24-02-32-10-685 iniciado. Revisa el estado en la consola de SageMaker.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "role = \"arn:aws:iam::004082821794:role/SageMakerExecutionRole\"  \n",
    "region = sagemaker.Session().boto_region_name\n",
    "bucket = 'fraud-detection-challenge-2025'  #Bucket S3\n",
    "output_path = f's3://{bucket}/output'  \n",
    "\n",
    "#Definir la ubicación del CSV en S3\n",
    "train_data_path = f's3://{bucket}/credit_risk_processed_train.csv'\n",
    "\n",
    "#Configurar el modelo XGBoost\n",
    "xgboost_container = sagemaker.image_uris.retrieve(\"xgboost\", region, version=\"1.5-1\")\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgboost_container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    volume_size=5,  # Como elegiste 5 GB\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker.Session(),\n",
    "    max_run=3600  # Máximo 1 hora\n",
    ")\n",
    "\n",
    "#Configurar hiperparámetros\n",
    "xgb.set_hyperparameters(\n",
    "    objective='binary:logistic',\n",
    "    num_round=100,\n",
    "    max_depth=6,\n",
    "    eta=0.2,\n",
    "    subsample=0.8\n",
    ")\n",
    "\n",
    "#Definir los datos de entrada\n",
    "train_input = TrainingInput(train_data_path, content_type='csv')\n",
    "\n",
    "#Lanzar el training job\n",
    "xgb.fit({'train': train_input})\n",
    "\n",
    "print(f\"Training job {xgb.latest_training_job.name} iniciado. Revisa el estado en la consola de SageMaker.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198f50d",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599814e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Precision: 0.77\n",
      "Recall: 0.81\n",
      "F1-Score: 0.79\n",
      "AUC-ROC: 0.74\n",
      "Confusion Matrix:\n",
      " [[ 40  31]\n",
      " [ 25 104]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "#Cargar el modelo desde S3\n",
    "model = xgb.Booster()\n",
    "model.load_model('model/xgboost-model')  # Ajusta la ruta\n",
    "\n",
    "#Cargar datos de validación\n",
    "data = pd.read_csv('credit_risk_processed_test.csv', header=None)\n",
    "X = data.iloc[:, 1:].values  # Todas menos la primera columna\n",
    "y = data.iloc[:, 0].values   # Primera columna como target\n",
    "    \n",
    "#Predecir\n",
    "dmatrix = xgb.DMatrix(X)\n",
    "predictions = model.predict(dmatrix)\n",
    "binary_predictions = (predictions >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, binary_predictions)\n",
    "precision = precision_score(y, binary_predictions)\n",
    "recall = recall_score(y, binary_predictions)\n",
    "f1 = f1_score(y, binary_predictions)\n",
    "auc = roc_auc_score(y, predictions)\n",
    "conf_matrix = confusion_matrix(y, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be119d99",
   "metadata": {},
   "source": [
    "Despliegue del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8ba0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo configurado con éxito.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: ml.m4.xlarge.\n",
      "INFO:sagemaker:Created S3 bucket: sagemaker-us-east-1-004082821794\n",
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2025-07-24-03-20-17-086\n",
      "INFO:sagemaker:Creating endpoint-config with name sagemaker-xgboost-2025-07-24-03-20-18-825\n",
      "INFO:sagemaker:Creating endpoint with name sagemaker-xgboost-2025-07-24-03-20-18-825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!Endpoint desplegado. Nombre: sagemaker-xgboost-2025-07-24-03-20-18-825\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.xgboost.model import XGBoostModel\n",
    "\n",
    "role = \"arn:aws:iam::004082821794:role/SageMakerExecutionRole\"\n",
    "\n",
    "#Definir la ruta del modelo en S3 (ajusta con la ruta exacta de tu job)\n",
    "model_data = 's3://fraud-detection-challenge-2025/output/sagemaker-xgboost-2025-07-24-02-32-10-685/output/model.tar.gz'\n",
    "\n",
    "model = XGBoostModel(\n",
    "    model_data=model_data,\n",
    "    role=role,\n",
    "    framework_version='1.5-1'  # Versión usada en el training\n",
    ")\n",
    "\n",
    "print(\"Modelo configurado con éxito.\")\n",
    "\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,  \n",
    "    instance_type='ml.m4.xlarge'  \n",
    ")\n",
    "\n",
    "print(f\"Endpoint desplegado. Nombre: {predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc2c607",
   "metadata": {},
   "source": [
    "Pruebas de inferencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "babebf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72\n",
      "Precision: 0.77\n",
      "Recall: 0.81\n",
      "F1-Score: 0.79\n",
      "AUC-ROC: 0.74\n",
      "Confusion Matrix:\n",
      " [[ 40  31]\n",
      " [ 25 104]]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "import numpy as np\n",
    "\n",
    "endpoint_name = 'sagemaker-xgboost-2025-07-24-03-20-18-825'\n",
    "\n",
    "#Configurar el predictor\n",
    "predictor = Predictor(endpoint_name=endpoint_name, serializer=CSVSerializer())\n",
    "\n",
    "data = pd.read_csv('credit_risk_processed_test.csv', header=None)\n",
    "X = data.iloc[:, 1:].values  \n",
    "y = data.iloc[:, 0].values   #Primera columna como target\n",
    "\n",
    "#Invocar el endpoint\n",
    "response = predictor.predict(X)\n",
    "predictions = np.fromstring(response.decode('utf-8'), sep='\\n')\n",
    "binary_predictions = (predictions >= 0.5).astype(int)\n",
    "\n",
    "accuracy = accuracy_score(y, binary_predictions)\n",
    "precision = precision_score(y, binary_predictions)\n",
    "recall = recall_score(y, binary_predictions)\n",
    "f1 = f1_score(y, binary_predictions)\n",
    "auc = roc_auc_score(y, predictions)\n",
    "conf_matrix = confusion_matrix(y, binary_predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "print(f\"AUC-ROC: {auc:.2f}\")\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
